{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaeb6e6b-ad22-4ecf-96d5-bf77c0ab8f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:23:57.713166500Z",
     "start_time": "2024-02-19T07:23:55.866614700Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8034ebaedcaf9f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:23:57.718125300Z",
     "start_time": "2024-02-19T07:23:57.714617800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_location = \"/Users/Xutao/Documents/CR4CR/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82b57466-1a3d-4625-aac0-c16a53e4035f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:23:57.840541800Z",
     "start_time": "2024-02-19T07:23:57.716126Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(dataset_location + \"Market 00abc_240310.xlsx\")\n",
    "# Since there are some null responses will a score of 0, we want to replace them with empty strings\n",
    "df.fillna(\"\", inplace=True)\n",
    "\n",
    "# select only the three responses columns and the score column\n",
    "response_columns = [\"Market.00a_OE\", \"Market.00bc_OE\", \"Market.00bc_OE follow up\"]\n",
    "score_column = [\"Score\"]\n",
    "df = df[[\"Respondent Id\", \"Administration\"] + response_columns + score_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ab1ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    # text = text.lower()\n",
    "\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    #text = re.sub(r'^\\w+\\s*$', '',text)\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\+\\-\\s]', ' ', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def preprocess_text1(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # text = re.sub(r'\\n', ' ', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Preprocess the text in the response columns\n",
    "for column in response_columns:\n",
    "    df[column] = df[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2976ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent Id</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Market.00a_OE</th>\n",
       "      <th>Market.00bc_OE</th>\n",
       "      <th>Market.00bc_OE follow up</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24977</td>\n",
       "      <td>Spr 23</td>\n",
       "      <td>Number of people inside the shop, number of pe...</td>\n",
       "      <td>Number of people inside the shop and number of...</td>\n",
       "      <td>We will definitively need to know the amount o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25149</td>\n",
       "      <td>Spr 23</td>\n",
       "      <td>what causes a door to open automatically.</td>\n",
       "      <td>what can cause a door to open automatically</td>\n",
       "      <td>i think this piece of information is important...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22791</td>\n",
       "      <td>Spr 23</td>\n",
       "      <td>How many people are going through the doors. H...</td>\n",
       "      <td>How long it will take for everyone to go throu...</td>\n",
       "      <td>We must know this information to decrease the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22796</td>\n",
       "      <td>Spr 23</td>\n",
       "      <td>The groups of customers that might go in, the ...</td>\n",
       "      <td>customers that go in and leave</td>\n",
       "      <td>Because we need to how many customers go in, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23062</td>\n",
       "      <td>Spr 23</td>\n",
       "      <td>How big is the store, as a team of constructio...</td>\n",
       "      <td>What does the owner want.\\nHow tall the store ...</td>\n",
       "      <td>This can impact how the finished product will ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Respondent Id Administration  \\\n",
       "0          24977         Spr 23   \n",
       "1          25149         Spr 23   \n",
       "2          22791         Spr 23   \n",
       "3          22796         Spr 23   \n",
       "4          23062         Spr 23   \n",
       "\n",
       "                                       Market.00a_OE  \\\n",
       "0  Number of people inside the shop, number of pe...   \n",
       "1          what causes a door to open automatically.   \n",
       "2  How many people are going through the doors. H...   \n",
       "3  The groups of customers that might go in, the ...   \n",
       "4  How big is the store, as a team of constructio...   \n",
       "\n",
       "                                      Market.00bc_OE  \\\n",
       "0  Number of people inside the shop and number of...   \n",
       "1        what can cause a door to open automatically   \n",
       "2  How long it will take for everyone to go throu...   \n",
       "3                     customers that go in and leave   \n",
       "4  What does the owner want.\\nHow tall the store ...   \n",
       "\n",
       "                            Market.00bc_OE follow up  Score  \n",
       "0  We will definitively need to know the amount o...      3  \n",
       "1  i think this piece of information is important...      0  \n",
       "2  We must know this information to decrease the ...      1  \n",
       "3  Because we need to how many customers go in, a...      1  \n",
       "4  This can impact how the finished product will ...      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26b27931faef3920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:23:58.626445800Z",
     "start_time": "2024-02-19T07:23:58.623964900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['concat_response'] = df.iloc[:,2] + ' [SEP] ' + df.iloc[:,3] + ' [SEP] ' + df.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d363a-6afb-49cd-b7d3-8f04402e9058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:23:59.180408300Z",
     "start_time": "2024-02-19T07:23:59.178404300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cbdeca1-31cc-4234-8c9a-8adab030c774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:23:59.876387100Z",
     "start_time": "2024-02-19T07:23:59.866759300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, DistilBertPreTrainedModel, RobertaForSequenceClassification\n",
    "#from transformers.modeling_distilbert import DistilBertModel, DistilBertPreTrainedModel\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class DistilRobertaClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DistilRobertaClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('distilroberta-base')\n",
    "        self.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        roberta_output = outputs[0]\n",
    "\n",
    "        cls_output = roberta_output[:, 0]\n",
    "        logits = self.classifier(cls_output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "\n",
    "class RobertaDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.columns = [\"concat_response\"]\n",
    "        self.labels = self.dataframe['Score'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
    "        row = self.dataframe.iloc[index]\n",
    "        response = row['concat_response']\n",
    "        score = row['Score']\n",
    "\n",
    "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
    "        encoding_a = self.tokenizer.encode_plus(response, add_special_tokens=True, max_length=self.max_length, padding='max_length', return_attention_mask=True, truncation=True)\n",
    "\n",
    "        return {\n",
    "            'input_ids_a': torch.tensor(encoding_a['input_ids'], dtype=torch.long),\n",
    "            'attention_mask_a': torch.tensor(encoding_a['attention_mask'], dtype=torch.long),\n",
    "            'score': torch.tensor(score, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a16ad61-45cd-401e-b4b4-20835e996ad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:37:57.570064400Z",
     "start_time": "2024-02-19T07:24:03.504065300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilRobertaClassifier(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base', output_attentions=False)\n",
    "\n",
    "# First split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['Score'], random_state=42)\n",
    "\n",
    "#\n",
    "# Create datasets\n",
    "train_dataset = RobertaDataset(train_df, tokenizer)\n",
    "test_dataset = RobertaDataset(test_df, tokenizer)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8)  # changed batch_size to 3\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)  # new line, changed batch_size to 3\n",
    "\n",
    "model = DistilRobertaClassifier(5)\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa5fc417e85ba284",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T07:39:07.809637400Z",
     "start_time": "2024-02-19T07:39:07.803971Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 478 entries, 550 to 328\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Respondent Id             478 non-null    int64 \n",
      " 1   Administration            478 non-null    object\n",
      " 2   Market.00a_OE             478 non-null    object\n",
      " 3   Market.00bc_OE            478 non-null    object\n",
      " 4   Market.00bc_OE follow up  478 non-null    object\n",
      " 5   Score                     478 non-null    int64 \n",
      " 6   concat_response           478 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 29.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0dd2010-041c-497a-8beb-331353bd97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = nn.MSELoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9889290-8d2c-408f-90ce-453f0b43f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.33\n",
      "Average training loss: 0.84\n",
      "Average training loss: 0.63\n",
      "Average training loss: 0.48\n",
      "Average training loss: 0.37\n",
      "Average training loss: 0.31\n",
      "Average training loss: 0.26\n",
      "Average training loss: 0.17\n",
      "Average training loss: 0.11\n",
      "Average training loss: 0.11\n",
      "Average training loss: 0.09\n",
      "Average training loss: 0.10\n",
      "Average training loss: 0.06\n",
      "Average training loss: 0.11\n",
      "Average training loss: 0.04\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            batch['input_ids_a'].to(device), batch['attention_mask_a'].to(device)\n",
    "        )\n",
    "        loss = loss_function(outputs, batch['score'].to(device).long())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c130e5ffad82ae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b0039cb-45f7-483d-8c2a-dc6c95c2e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 58.33%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "      # Forward pass\n",
    "      outputs = model(\n",
    "          batch['input_ids_a'].to(device), batch['attention_mask_a'].to(device)\n",
    "      )\n",
    "      #all_predictions.extend(outputs.cpu().numpy())\n",
    "      #all_labels.extend(batch['score'].numpy())\n",
    "\n",
    "      _, outputs = torch.max(outputs, 1)\n",
    "      all_predictions.extend(outputs.cpu().numpy())\n",
    "      all_labels.extend(batch['score'].numpy())\n",
    "\n",
    "# Since my predictions return float number, such as 2.3 and 3.5, I decide to round\n",
    "# or map the number in the following way:\n",
    "# 2.5 -> 3; 2.3 -> 2; to get a better algorithm to calculate the accuracy\n",
    "\n",
    "def arrayround(arr,n=0):\n",
    "    import numpy as np\n",
    "    flag = np.where(arr>=0,1,-1)\n",
    "    arr = np.abs(arr)\n",
    "    arr10 = arr*10**(n+1)\n",
    "    arr20 = np.floor(arr10)\n",
    "    arr30 = np.where(arr20%10==5,(arr20+1)/10**(n+1),arr20/10**(n+1))\n",
    "    result = np.around(arr30,n)\n",
    "    return result*flag\n",
    "\n",
    "all_predictions = np.array(all_predictions).flatten()\n",
    "#all_predictions = arrayround(all_predictions)\n",
    "\n",
    "\n",
    "\n",
    "# Compute the average accuracy over all batches\n",
    "correct_predictions = sum(all_predictions == np.array(all_labels))\n",
    "total_predictions = len(all_predictions)\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d847e1b4-e110-4b6e-8ac2-4b15eb1ebb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
